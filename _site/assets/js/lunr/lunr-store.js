var store = [{
        "title": "AutoRL: AutoML for RL",
        "excerpt":"TL;DR: An overview of research on AutoRL in 2021 by the AutoML Freiburg group.  ","categories": ["Blog"],
        "tags": ["link","AutoML.org"],
        "url": "/blog/autorl-automllink/",
        "teaser": null
      },{
        "title": "Self-Paced Context Evaluation for Contextual Reinforcement Learning",
        "excerpt":"TL;DR: We propose SPaCE, a general approach that can be deployed for any agent with a value function and task instances identified by their context without any additional information. We believe this is an important factor in future applications, including AutoML where in-depth knowledge about target algorithm instances is not...","categories": ["Blog"],
        "tags": ["link","AutoML.org"],
        "url": "/blog/space-automllink/",
        "teaser": null
      },{
        "title": "Theory-Inspired Parameter Control Benchmarks for DAC",
        "excerpt":"TL;DR: New toy benchmarks enable better study of RL agents performance and allows us to compare against ground truth optimal policies.  ","categories": ["Blog"],
        "tags": ["link","demo"],
        "url": "/blog/theodac-andrelink/",
        "teaser": null
      },{
        "title": "TempoRL - Learning When to Act",
        "excerpt":"TL;DR: Jointly learning when and how to act improves sample efficiency of RL agents through better exploration and improved exploitation.  ","categories": ["Blog"],
        "tags": ["link","demo"],
        "url": "/blog/ztemporl-andrelink/",
        "teaser": null
      },{
        "title": "Understanding AutoRL Hyperparameter Landscapes",
        "excerpt":"TL;DR: We investigate hyperparameters in RL by building landscapes of algorithm performance for different hyperparameter values at different stages of training. Using these landscapes we empirically demonstrate that adjusting hyperparameters during training can improve performance, which opens up new avenues to build better dynamic optimizers for RL.  ","categories": ["Blog"],
        "tags": ["link","AutoML.org"],
        "url": "/blog/landscapes-automllink/",
        "teaser": null
      },{
        "title": "Contextualize Me – The Case for Context in Reinforcement Learning",
        "excerpt":"TL;DR: We can model and investigate generalization in RL with contextual RL and our benchmark library CARL. In theory, without adding context we cannot achieve optimal performance and in the experiments we saw that using context information can indeed be beneficial – context matters!  ","categories": ["Blog"],
        "tags": ["link","AutoML.org"],
        "url": "/blog/contextualizeme-automllink/",
        "teaser": null
      },{
        "title": "Hyperparameter Tuning in Reinforcement Learning is Easy, Actually",
        "excerpt":"TL;DR: Hyperparameter Optimization tools perform well on Reinforcement Learning, outperforming Grid Searches with less than 10% of the budget. If not reported correctly, however, all hyperparameter tuning can heavily skew future comparisons.  ","categories": ["Blog"],
        "tags": ["link","AutoML.org"],
        "url": "/blog/hpoinrl-automllink/",
        "teaser": null
      },{
        "title": "2023 in AutoRL",
        "excerpt":"TL;DR: From combining RL with LLMs through more efficient MetaRL and updates in an environment design to classic hyperparameter optimization, these are some of our top picks, plus a selection of our own AutoRL projects at the end of this post. So sit back and enjoy some of the most...","categories": ["Blog"],
        "tags": ["Review",2023],
        "url": "/blog/retrospective/",
        "teaser": null
      },{
        "title": "AutoRL Workshop at ICML 2024, Vienna",
        "excerpt":"Announcing the AutoRL workshop at ICML 2024, Vienna We are excited to announce that the first AutoRL workshop was accepted at ICML to be held in Vienna this year. The workshop website contains more details. The workshops page for ICML is here and the AutoRL workshop page on the ICML...","categories": ["Blog"],
        "tags": ["Workshop",2024],
        "url": "/blog/autorl-workshop/",
        "teaser": null
      },{
        "title": "Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization",
        "excerpt":"TL;DR: A new contextual world-model that helps to generalize better to new scenarios by understanding contextual factors like robot mass or strength. This contextual Dreamer outperforms existing approaches in both familiar and unfamiliar situations.  ","categories": ["Blog"],
        "tags": ["link","AutoML.org"],
        "url": "/blog/contextdreamer-automllink/",
        "teaser": null
      },{
        "title": "Optimising Smarter: Joint Optimisation of RL Hyperparameters and Reward Shape",
        "excerpt":"TL;DR: Jointly optimising hyperparameters and reward shapes in RL outperforms separate tuning, delivering better performance and stability, even in complex environments like Robosuite Wipe. No hand-tuning required! Optimising Smarter: Joint Optimisation of RL Hyperparameters and Reward Shape RL has achieved remarkable advancements, but one basic challenge remains ever-present: tuning hyperparameters...","categories": ["Blog"],
        "tags": ["Paper",2024],
        "url": "/blog/combined-optimisation/",
        "teaser": null
      },{
        "title": "2024 in AutoRL",
        "excerpt":"TL;DR: From integrating RL with VLMs and LLMs to hyperparameter tuning, environment design, and generalization, 2024 was packed with innovation. We’ve highlighted top advancements in AutoRL and included a selection of our own projects at the end. Dive in to explore the cutting-edge in RL from the past year! Making...","categories": ["Blog"],
        "tags": ["Review",2024],
        "url": "/blog/retrospective-24/",
        "teaser": null
      }]
